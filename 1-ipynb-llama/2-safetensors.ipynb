{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# safetensors conversion\n",
    "\n",
    "Llama tensors are serialized in `safetensors` format. For Llama 3 1B model, the tensors are encoded in `bfloat16`.\n",
    "\n",
    "`bfloat16` cannot be used on CPU, we need to convert them to `float32`. `bfloat16`s are just tuncated `float32`s : the lower bits of the fraction are truncated. We will simply pad each `bfloat16` with two `0` bytes and cast the result to `float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/eric/Projects/too-many-llama/.venv/lib/python3.13/site-packages (2.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_files = [\n",
    "    \"https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/model.safetensors\",\n",
    "    \"https://huggingface.co/meta-llama/Llama-3.2-1B/blob/main/config.json\"\n",
    "]\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "for required_file in required_files:\n",
    "    local_file = required_file.split(\"/\")[-1]\n",
    "    if not Path(local_file).exists():\n",
    "        with open(\"HF_TOKEN\") as f:\n",
    "            HF_TOKEN = f.read()\n",
    "\n",
    "        display(f\"Downloading {local_file}\")\n",
    "\n",
    "        opener = urllib.request.build_opener()\n",
    "        opener.addheaders = [(\"Authorization\", f\"Bearer {HF_TOKEN}\")]\n",
    "        urllib.request.install_opener(opener)\n",
    "\n",
    "        urllib.request.urlretrieve(required_file, local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfloat16_to_float32(bf16buffer: bytes) -> bytes:\n",
    "    assert len(bf16buffer) % 2 == 0, \"the bfloat16 buffer should have an even number of bytes\"\n",
    "    # bfloat16 are fraction-truncated float32s. just add zeros to convert them to float32\n",
    "    result = bytearray(len(bf16buffer) * 2)\n",
    "    for i in range(0, len(bf16buffer), 2):\n",
    "        # endianness: little-endian\n",
    "        # BF16: 2 bytes : [ B0, B1 ]\n",
    "        # Float32: 4bytes : [0, 0, B0, B1]\n",
    "        result[i * 2 + 2: i * 2 + 4] = bf16buffer[i : i + 2]\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import struct\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model_dir = Path(\"model\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "    with open(\"model.safetensors\", mode=\"rb\") as file:\n",
    "        # See safetensors file format : https://github.com/huggingface/safetensors\n",
    "        mmaped = mmap.mmap(file.fileno(), 0, prot=mmap.PROT_READ)\n",
    "        header_size = mmaped[:8]\n",
    "        header_size = struct.unpack(\"<Q\", header_size)[0] # little-endinan uint64\n",
    "        header = mmaped[8 : 8 + header_size]\n",
    "        header = json.loads(header)\n",
    "        for tensor_name, tensor_metadata in header.items():\n",
    "            if tensor_name == \"__metadata__\":\n",
    "                continue\n",
    "\n",
    "            start, end = tensor_metadata[\"data_offsets\"]\n",
    "\n",
    "            # header size should must be taken into account:\n",
    "            start += 8 + header_size\n",
    "            end += 8 + header_size\n",
    "\n",
    "            dtype = tensor_metadata[\"dtype\"]\n",
    "            print(f\"Extracting {tensor_name}, {start}, {end}\")\n",
    "            if dtype == \"BF16\":\n",
    "                raw_tensor = bfloat16_to_float32(mmaped[start: end])\n",
    "                with open(model_dir / f\"{tensor_name}.raw\", mode=\"wb\") as file:\n",
    "                    file.write(raw_tensor)\n",
    "        with open(model_dir / \"metadata.json\", mode=\"w\") as file:\n",
    "            json.dump(header, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_model(path: str):\n",
    "    model_dir = Path(path)\n",
    "    model = {}\n",
    "    with open(model_dir / \"metadata.json\") as file:\n",
    "        metadata = json.load(file)\n",
    "    for tensor_name, tensor_metadata in metadata.items():\n",
    "        if tensor_name == \"__metadata__\":\n",
    "            continue\n",
    "        file = open(model_dir / f\"{tensor_name}.raw\", mode=\"rb\")\n",
    "        mmaped = mmap.mmap(file.fileno(), 0, prot=mmap.PROT_READ)\n",
    "        model[tensor_name] = np.frombuffer(mmaped, dtype=np.float32).reshape(tensor_metadata[\"shape\"])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_raw_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128256, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"model.embed_tokens.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model.embed_tokens.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.norm.weight'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model[\"model.layers.0.input_layernorm.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.transpose().shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
